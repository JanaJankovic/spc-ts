{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d7d193e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.train.main as train_pipeline\n",
    "import src.models.model as model_handler\n",
    "from src.train.utils import get_parameters\n",
    "import src.logs.utils as log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb05f9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = {\n",
    "    'load_path': 'data/processed/mm118648.csv',\n",
    "    'm': 336,\n",
    "    'n': 14,\n",
    "    'lookback': 336,\n",
    "    'horizon': 1,\n",
    "    'target_col': 'load',\n",
    "    'time_col': 'datetime',\n",
    "    'freq': '1h',\n",
    "    'use_calendar': True,\n",
    "    'use_weather': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faae99e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 Trial 1/2\n",
      "🧠 Initializing base and residual models: base_residual\n",
      "🧼 Smoothing and cleaning target column 'load'...\n",
      "⏱ Resampling to 1h and summing...\n",
      "📈 Applying 336-window Simple Moving Average...\n",
      "🚫 Replaced 1562 outliers with average of top 336 values: 11.48\n",
      "✅ Target cleaned and ready.\n",
      "🌤️ Preprocessing weather data from 'c:\\Users\\janav\\Documents\\spc-ts\\data\\processed\\slovenia_weather.csv'...\n",
      "📅 Parsed and set index to datetime.\n",
      "📏 Ensured full datetime range with 42048 time steps.\n",
      "🔧 Interpolated missing values with method='time'\n",
      "✅ Weather data preprocessing complete.\n",
      "🔗 Joining load and weather data...\n",
      "📅 Parsed and sorted load data timestamps.\n",
      "📏 Full date range inferred: 2015-08-12 00:00:00 to 2020-05-28 23:00:00\n",
      "🔧 Interpolated missing values in load data\n",
      "🌦️ Prepared and sorted weather data index.\n",
      "✅ Joined DataFrame shape: (42048, 17)\n",
      "📦 Starting data loader preparation...\n",
      "🔄 Using multivariate scaling with one-hot encoding...\n",
      "🔣 One-hot encoding columns: ['day_of_week', 'month', 'is_weekend', 'hour', 'is_night', 'is_holiday']\n",
      "✅ Columns to encode: ['day_of_week', 'month', 'is_weekend', 'hour', 'is_night', 'is_holiday']\n",
      "🎯 One-hot encoding complete. New shape: (42048, 55)\n",
      "🔀 Splitting DataFrame with ratios (0.6, 0.1, 0.3)\n",
      "📊 Split sizes: Train=25228, Val=4204, Test=12616\n",
      "📏 Scaling multivariate data (target: 'load') using MinMaxScaler.\n",
      "🧹 Dropping non-numeric columns from train set: ['datetime']\n",
      "🧹 Dropping non-numeric columns from val set: ['datetime']\n",
      "🧹 Dropping non-numeric columns from test set: ['datetime']\n",
      "🔧 Splitting features and target...\n",
      "⚙️ Fitting and transforming training set...\n",
      "📐 Transforming validation and test sets...\n",
      "✅ Scaling complete. Shapes:\n",
      "   Train: (25228, 54), Val: (4204, 54), Test: (12616, 54)\n",
      "🔧 Building traditional sequences...\n",
      "🧱 Building traditional sequences (lookback=336, horizon=1, target='load')\n",
      "  🔄 Progress: 24665/24891 sequences\n",
      "✅ Sequence creation complete. Total sequences: 24891\n",
      "🧱 Building traditional sequences (lookback=336, horizon=1, target='load')\n",
      "  🔄 Progress: 3665/3867 sequences\n",
      "✅ Sequence creation complete. Total sequences: 3867\n",
      "🧱 Building traditional sequences (lookback=336, horizon=1, target='load')\n",
      "  🔄 Progress: 11665/12279 sequences\n",
      "✅ Sequence creation complete. Total sequences: 12279\n",
      "📐 Shapes - X_train: (24891, 336, 54), y_train: (24891, 1)\n",
      "📐 Shapes - X_val:   (3867, 336, 54), y_val:   (3867, 1)\n",
      "📐 Shapes - X_test:  (12279, 336, 54), y_test:  (12279, 1)\n",
      "📤 Creating DataLoaders...\n",
      "✅ DataLoaders ready.\n",
      "🚀 Training base model...\n",
      "🧼 Smoothing and cleaning target column 'load'...\n",
      "⏱ Resampling to 1h and summing...\n",
      "📈 Applying 336-window Simple Moving Average...\n",
      "🚫 Replaced 1562 outliers with average of top 336 values: 11.48\n",
      "✅ Target cleaned and ready.\n",
      "🌤️ Preprocessing weather data from 'c:\\Users\\janav\\Documents\\spc-ts\\data\\processed\\slovenia_weather.csv'...\n",
      "📅 Parsed and set index to datetime.\n",
      "📏 Ensured full datetime range with 42048 time steps.\n",
      "🔧 Interpolated missing values with method='time'\n",
      "✅ Weather data preprocessing complete.\n",
      "🔗 Joining load and weather data...\n",
      "📅 Parsed and sorted load data timestamps.\n",
      "📏 Full date range inferred: 2015-08-12 00:00:00 to 2020-05-28 23:00:00\n",
      "🔧 Interpolated missing values in load data\n",
      "🌦️ Prepared and sorted weather data index.\n",
      "✅ Joined DataFrame shape: (42048, 17)\n",
      "📦 Starting data loader preparation...\n",
      "🔄 Using multivariate scaling with one-hot encoding...\n",
      "🔣 One-hot encoding columns: ['day_of_week', 'month', 'is_weekend', 'hour', 'is_night', 'is_holiday']\n",
      "✅ Columns to encode: ['day_of_week', 'month', 'is_weekend', 'hour', 'is_night', 'is_holiday']\n",
      "🎯 One-hot encoding complete. New shape: (42048, 55)\n",
      "🔀 Splitting DataFrame with ratios (0.6, 0.1, 0.3)\n",
      "📊 Split sizes: Train=25228, Val=4204, Test=12616\n",
      "📏 Scaling multivariate data (target: 'load') using MinMaxScaler.\n",
      "🧹 Dropping non-numeric columns from train set: ['datetime']\n",
      "🧹 Dropping non-numeric columns from val set: ['datetime']\n",
      "🧹 Dropping non-numeric columns from test set: ['datetime']\n",
      "🔧 Splitting features and target...\n",
      "⚙️ Fitting and transforming training set...\n",
      "📐 Transforming validation and test sets...\n",
      "✅ Scaling complete. Shapes:\n",
      "   Train: (25228, 54), Val: (4204, 54), Test: (12616, 54)\n",
      "🔧 Building traditional sequences...\n",
      "🧱 Building traditional sequences (lookback=336, horizon=1, target='load')\n",
      "  🔄 Progress: 24665/24891 sequences\n",
      "✅ Sequence creation complete. Total sequences: 24891\n",
      "🧱 Building traditional sequences (lookback=336, horizon=1, target='load')\n",
      "  🔄 Progress: 3665/3867 sequences\n",
      "✅ Sequence creation complete. Total sequences: 3867\n",
      "🧱 Building traditional sequences (lookback=336, horizon=1, target='load')\n",
      "  🔄 Progress: 11665/12279 sequences\n",
      "✅ Sequence creation complete. Total sequences: 12279\n",
      "📐 Shapes - X_train: (24891, 336, 54), y_train: (24891, 1)\n",
      "📐 Shapes - X_val:   (3867, 336, 54), y_val:   (3867, 1)\n",
      "📐 Shapes - X_test:  (12279, 336, 54), y_test:  (12279, 1)\n",
      "📤 Creating DataLoaders...\n",
      "✅ DataLoaders ready.\n",
      "🟦 [Train] Batch 778/778 - Loss: 0.0417\n",
      "🟨 [Eval ] Batch 121/121 - Loss: 0.1716\n",
      "📈 Epoch 1/30 - Train Loss: 0.0927, Val Loss: 0.0748\n",
      "🟦 [Train] Batch 778/778 - Loss: 0.0146\n",
      "🟨 [Eval ] Batch 121/121 - Loss: 0.1501\n",
      "📈 Epoch 2/30 - Train Loss: 0.0678, Val Loss: 0.0693\n",
      "🟦 [Train] Batch 403/778 - Loss: 0.0689\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m log\u001b[38;5;241m.\u001b[39mcreate_logs_files()\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtrain_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbase_residual\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_base_residual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparam_sampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbase_residual\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\janav\\Documents\\spc-ts\\src\\train\\main.py:35\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model_type, model_fn, data_config, param_sampler, trials, epochs, early_stopping, device)\u001b[0m\n\u001b[0;32m     31\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_t\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     33\u001b[0m     log_trial_info(model_name, model_type, trial, params)\n\u001b[1;32m---> 35\u001b[0m     \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_component\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtracker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtracker\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m🏁 All trials complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\janav\\Documents\\spc-ts\\src\\train\\pipelines\\residual.py:206\u001b[0m, in \u001b[0;36mtrain_residual_pipeline\u001b[1;34m(model_name, model_type, model_fn, data_config, params, epochs, device, tracker, model_component)\u001b[0m\n\u001b[0;32m    198\u001b[0m scaler, (train_loader, val_loader, test_loader), (base_model, residual_model), (_, residual_optimizer), _ \u001b[38;5;241m=\u001b[39m model_fn(\n\u001b[0;32m    199\u001b[0m     data_config, params\n\u001b[0;32m    200\u001b[0m )\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🚀 Training base model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    203\u001b[0m base_model \u001b[38;5;241m=\u001b[39m standard_train_pipeline(\n\u001b[0;32m    204\u001b[0m     model_name\u001b[38;5;241m=\u001b[39mmodel_name,\n\u001b[0;32m    205\u001b[0m     model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m--> 206\u001b[0m     model_component\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    207\u001b[0m     model_fn\u001b[38;5;241m=\u001b[39mmodel_fn,\n\u001b[0;32m    208\u001b[0m     data_config\u001b[38;5;241m=\u001b[39mdata_config,\n\u001b[0;32m    209\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    210\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m    211\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[0;32m    212\u001b[0m     tracker\u001b[38;5;241m=\u001b[39mtracker\n\u001b[0;32m    213\u001b[0m )\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m📉 Computing residuals from base predictions...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    216\u001b[0m residual_dataset \u001b[38;5;241m=\u001b[39m compute_residual_dataset(base_model, train_loader, scaler, device)\n",
      "File \u001b[1;32mc:\\Users\\janav\\Documents\\spc-ts\\src\\train\\pipelines\\standard.py:99\u001b[0m, in \u001b[0;36mstandard_train_pipeline\u001b[1;34m(model_name, model_type, model_component, model_fn, data_config, params, epochs, device, tracker)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     98\u001b[0m     train_loss, train_preds, train_targets \u001b[38;5;241m=\u001b[39m train_one_epoch(\n\u001b[1;32m---> 99\u001b[0m         model, train_loader, criterion, optimizer, device\n\u001b[0;32m    100\u001b[0m     )\n\u001b[0;32m    101\u001b[0m     etr \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    103\u001b[0m     svl \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Users\\janav\\Documents\\spc-ts\\src\\train\\pipelines\\standard.py:31\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, train_loader, criterion, optimizer, device)\u001b[0m\n\u001b[0;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     30\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 31\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     33\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m targets\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     34\u001b[0m all_preds\u001b[38;5;241m.\u001b[39mappend(preds\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu())\n",
      "File \u001b[1;32mc:\\Users\\janav\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\janav\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\janav\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "log.create_logs_files()\n",
    "\n",
    "train_pipeline.train_model(\n",
    "    'base_residual',\n",
    "    model_fn=lambda config, p: model_handler.get_base_residual(config, p),\n",
    "    data_config=data_config,\n",
    "    param_sampler=lambda: get_parameters(\"base_residual\"),\n",
    "    trials=2,\n",
    "    epochs=30,\n",
    "    early_stopping=True,\n",
    "    device='cpu'\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
