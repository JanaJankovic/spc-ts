{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c44fcb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ Oldest date across all files: 2015-08-12\n",
      "üìÖ Newest date across all files: 2020-05-28\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "directory = 'raw'\n",
    "prefix = 'mm'\n",
    "ts_column = 'ts'\n",
    "\n",
    "pattern = os.path.join(directory, f\"{prefix}*.csv\")\n",
    "files = glob.glob(pattern)\n",
    "\n",
    "all_dates = []\n",
    "\n",
    "for file in files:\n",
    "    try:\n",
    "        df = pd.read_csv(file, sep=';', usecols=[ts_column])\n",
    "        dates = pd.to_datetime(df[ts_column], errors='coerce').dropna()\n",
    "        all_dates.extend(dates)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to read {os.path.basename(file)}: {e}\")\n",
    "\n",
    "if all_dates:\n",
    "    min_date = min(all_dates)\n",
    "    max_date = max(all_dates)\n",
    "    print(f\"üìÖ Oldest date across all files: {min_date.date()}\")\n",
    "    print(f\"üìÖ Newest date across all files: {max_date.date()}\")\n",
    "else:\n",
    "    print(\"‚ùå No valid 'ts' dates found in any mm*.csv file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff03e34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: Ljubljana\n",
      "Fetching: Maribor\n",
      "Fetching: Celje\n",
      "Fetching: Koper\n",
      "Fetching: Novo Mesto\n",
      "Saved to processed/slovenia_averaged_weather.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def fetch_open_meteo(city_name, lat, lon, start_date, end_date):\n",
    "    url = (\n",
    "        \"https://archive-api.open-meteo.com/v1/archive?\"\n",
    "        f\"latitude={lat}&longitude={lon}\"\n",
    "        f\"&start_date={start_date}&end_date={end_date}\"\n",
    "        f\"&hourly=temperature_2m,precipitation,surface_pressure,snowfall,\"\n",
    "        f\"shortwave_radiation,winddirection_10m,windgusts_10m,windspeed_10m,\"\n",
    "        f\"relative_humidity_2m&timezone=Europe%2FBerlin\"\n",
    "    )\n",
    "    print(f\"Fetching: {city_name}\")\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to fetch data for {city_name}: {response.text}\")\n",
    "\n",
    "    data = response.json()[\"hourly\"]\n",
    "    df = pd.DataFrame(data)\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"time\"])\n",
    "    df[\"city\"] = city_name\n",
    "    return df.drop(columns=[\"time\"])\n",
    "\n",
    "# Setup\n",
    "start = min_date.date()\n",
    "end = max_date.date()\n",
    "\n",
    "cities = {\n",
    "    \"Ljubljana\": (46.0569, 14.5058),\n",
    "    \"Maribor\": (46.5547, 15.6459),\n",
    "    \"Celje\": (46.2309, 15.2604),\n",
    "    \"Koper\": (45.5481, 13.7302),\n",
    "    \"Novo Mesto\": (45.8030, 15.1688)\n",
    "}\n",
    "\n",
    "# Fetch and concatenate\n",
    "dfs = [fetch_open_meteo(city, lat, lon, start, end) for city, (lat, lon) in cities.items()]\n",
    "all_data = pd.concat(dfs)\n",
    "\n",
    "# Aggregate to country level (mean)\n",
    "country_hourly = (\n",
    "    all_data\n",
    "    .drop(columns=[\"city\"])\n",
    "    .groupby(\"datetime\")\n",
    "    .mean(numeric_only=True)\n",
    "    .round(4)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "# Save\n",
    "country_hourly.to_csv(\"processed/slovenia_averaged_weather.csv\", index=False)\n",
    "print(\"Saved to processed/slovenia_averaged_weather.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6497dcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to processed/slovenia_holidays.csv\n"
     ]
    }
   ],
   "source": [
    "# Extract years from the date range\n",
    "start_year = start.year\n",
    "end_year = end.year\n",
    "\n",
    "dates = []\n",
    "for year in range(start_year, end_year + 1):\n",
    "    url = f\"https://date.nager.at/api/v3/publicholidays/{year}/SI\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        dates += [h[\"date\"] for h in response.json()]\n",
    "    except Exception as e:\n",
    "        print(f\"Failed for {year}: {e}\")\n",
    "\n",
    "# Deduplicate, sort, and save\n",
    "df = pd.DataFrame(sorted(set(dates)), columns=[\"holiday\"])\n",
    "df.to_csv(\"processed/slovenia_holidays.csv\", index=False)\n",
    "print(\"Saved to processed/slovenia_holidays.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0fba156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed: mm254.csv\n",
      "‚úÖ Processed: mm3371.csv\n",
      "‚úÖ Processed: mm4678.csv\n",
      "‚úÖ Processed: mm9725.csv\n",
      "‚úÖ Processed: mm41865.csv\n",
      "‚úÖ Processed: mm45674.csv\n",
      "‚úÖ Processed: mm57710.csv\n",
      "‚úÖ Processed: mm65924.csv\n",
      "‚úÖ Processed: mm72425.csv\n",
      "‚úÖ Processed: mm79158.csv\n",
      "‚úÖ Processed: mm118648.csv\n",
      "‚úÖ Processed: mm125431.csv\n",
      "‚úÖ Processed: mm144644.csv\n",
      "‚úÖ Processed: mm148296.csv\n",
      "‚úÖ Processed: mm166942.csv\n",
      "‚úÖ Processed: mm182972.csv\n",
      "‚úÖ Processed: mm187195.csv\n",
      "‚úÖ Processed: mm199762.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "raw_dir = 'raw'\n",
    "out_dir = 'processed'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "files = glob(os.path.join(raw_dir, '*.csv'))\n",
    "\n",
    "for file in files:\n",
    "    filename = os.path.basename(file)\n",
    "    try:\n",
    "        df = pd.read_csv(file, sep=';', usecols=['ts', 'vrednost'])\n",
    "\n",
    "        # Convert time and vrednost\n",
    "        df['ts'] = pd.to_datetime(df['ts'], errors='coerce')\n",
    "        df['vrednost'] = df['vrednost'].str.replace(',', '.', regex=False).astype(float)\n",
    "\n",
    "        # Group by date and compute average\n",
    "        df['date'] = df['ts'].dt.date\n",
    "        daily_avg = df.groupby('date', as_index=False)['vrednost'].mean()\n",
    "\n",
    "        # Sort by date\n",
    "        daily_avg = daily_avg.sort_values(by='date')\n",
    "\n",
    "        # Save to processed folder\n",
    "        out_path = os.path.join(out_dir, filename)\n",
    "        daily_avg.to_csv(out_path, index=False)\n",
    "        print(f\"‚úÖ Processed: {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed: {filename} ‚Äî {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
