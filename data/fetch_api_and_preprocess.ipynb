{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c44fcb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ Oldest date across all files: 2015-08-12\n",
      "üìÖ Newest date across all files: 2020-05-28\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "directory = 'raw'\n",
    "prefix = 'mm'\n",
    "ts_column = 'ts'\n",
    "\n",
    "pattern = os.path.join(directory, f\"{prefix}*.csv\")\n",
    "files = glob.glob(pattern)\n",
    "\n",
    "all_dates = []\n",
    "\n",
    "for file in files:\n",
    "    try:\n",
    "        df = pd.read_csv(file, sep=';', usecols=[ts_column])\n",
    "        dates = pd.to_datetime(df[ts_column], errors='coerce').dropna()\n",
    "        all_dates.extend(dates)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to read {os.path.basename(file)}: {e}\")\n",
    "\n",
    "if all_dates:\n",
    "    min_date = min(all_dates)\n",
    "    max_date = max(all_dates)\n",
    "    print(f\"üìÖ Oldest date across all files: {min_date.date()}\")\n",
    "    print(f\"üìÖ Newest date across all files: {max_date.date()}\")\n",
    "else:\n",
    "    print(\"‚ùå No valid 'ts' dates found in any mm*.csv file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff03e34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: Ljubljana\n",
      "Fetching: Maribor\n",
      "Fetching: Celje\n",
      "Fetching: Koper\n",
      "Fetching: Novo Mesto\n",
      "‚úÖ Saved to processed/slovenia_weather.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def fetch_open_meteo(city_name, lat, lon, start_date, end_date):\n",
    "    url = (\n",
    "        \"https://archive-api.open-meteo.com/v1/archive?\"\n",
    "        f\"latitude={lat}&longitude={lon}\"\n",
    "        f\"&start_date={start_date}&end_date={end_date}\"\n",
    "        f\"&hourly=temperature_2m,precipitation,surface_pressure,snowfall,\"\n",
    "        f\"shortwave_radiation,winddirection_10m,windgusts_10m,windspeed_10m,\"\n",
    "        f\"relative_humidity_2m&timezone=Europe%2FBerlin\"\n",
    "    )\n",
    "    print(f\"Fetching: {city_name}\")\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to fetch data for {city_name}: {response.text}\")\n",
    "\n",
    "    data = response.json()[\"hourly\"]\n",
    "    df = pd.DataFrame(data)\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"time\"])\n",
    "    df[\"city\"] = city_name\n",
    "    return df.drop(columns=[\"time\"])\n",
    "\n",
    "# Setup\n",
    "start = min_date.date()\n",
    "end = max_date.date()\n",
    "\n",
    "cities = {\n",
    "    \"Ljubljana\": (46.0569, 14.5058),\n",
    "    \"Maribor\": (46.5547, 15.6459),\n",
    "    \"Celje\": (46.2309, 15.2604),\n",
    "    \"Koper\": (45.5481, 13.7302),\n",
    "    \"Novo Mesto\": (45.8030, 15.1688)\n",
    "}\n",
    "\n",
    "# Fetch and combine\n",
    "dfs = [fetch_open_meteo(city, lat, lon, start, end) for city, (lat, lon) in cities.items()]\n",
    "all_data = pd.concat(dfs)\n",
    "\n",
    "# === Hourly aggregation to country level ===\n",
    "country_hourly = (\n",
    "    all_data\n",
    "    .drop(columns=[\"city\"])\n",
    "    .groupby(\"datetime\")\n",
    "    .mean(numeric_only=True)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# === Daily average ===\n",
    "# country_hourly[\"date\"] = country_hourly[\"datetime\"].dt.date\n",
    "# daily_avg = (\n",
    "#     country_hourly\n",
    "#     .drop(columns=[\"datetime\"])\n",
    "#     .groupby(\"date\", as_index=False)\n",
    "#     .mean(numeric_only=True)\n",
    "#     .sort_values(\"date\")\n",
    "# )\n",
    "\n",
    "# === Save ===\n",
    "country_hourly.to_csv(\"processed/slovenia_weather.csv\", index=False)\n",
    "print(\"‚úÖ Saved to processed/slovenia_weather.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6497dcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to processed/slovenia_holidays.csv\n"
     ]
    }
   ],
   "source": [
    "# Extract years from the date range\n",
    "start_year = start.year\n",
    "end_year = end.year\n",
    "\n",
    "dates = []\n",
    "for year in range(start_year, end_year + 1):\n",
    "    url = f\"https://date.nager.at/api/v3/publicholidays/{year}/SI\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        dates += [h[\"date\"] for h in response.json()]\n",
    "    except Exception as e:\n",
    "        print(f\"Failed for {year}: {e}\")\n",
    "\n",
    "# Deduplicate, sort, and save\n",
    "df = pd.DataFrame(sorted(set(dates)), columns=[\"holiday\"])\n",
    "df.to_csv(\"processed/slovenia_holidays.csv\", index=False)\n",
    "print(\"Saved to processed/slovenia_holidays.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1ecaed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed: mm118648.csv\n",
      "‚úÖ Processed: mm125431.csv\n",
      "‚úÖ Processed: mm144644.csv\n",
      "‚úÖ Processed: mm148296.csv\n",
      "‚úÖ Processed: mm166942.csv\n",
      "‚úÖ Processed: mm182972.csv\n",
      "‚úÖ Processed: mm187195.csv\n",
      "‚úÖ Processed: mm199762.csv\n",
      "‚úÖ Processed: mm254.csv\n",
      "‚úÖ Processed: mm3371.csv\n",
      "‚úÖ Processed: mm41865.csv\n",
      "‚úÖ Processed: mm45674.csv\n",
      "‚úÖ Processed: mm4678.csv\n",
      "‚úÖ Processed: mm57710.csv\n",
      "‚úÖ Processed: mm65924.csv\n",
      "‚úÖ Processed: mm72425.csv\n",
      "‚úÖ Processed: mm79158.csv\n",
      "‚úÖ Processed: mm9725.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "def fill_missing_time_mode_monthly(df, datetime_col='datetime', value_col='vrednost'):\n",
    "    import numpy as np\n",
    "\n",
    "    freq = \"15min\"\n",
    "    df = df.copy()\n",
    "    df[datetime_col] = pd.to_datetime(df[datetime_col])\n",
    "    df = df.set_index(datetime_col)\n",
    "    full_range = pd.date_range(df.index.min(), df.index.max(), freq=freq)\n",
    "    df = df.reindex(full_range)\n",
    "    df['month'] = df.index.month\n",
    "    df['dayofweek'] = df.index.dayofweek\n",
    "    df['hour'] = df.index.hour\n",
    "    df['minute'] = df.index.minute\n",
    "\n",
    "    # Drop NaNs before mode calculation!\n",
    "    mode_df = df.dropna(subset=[value_col])\n",
    "\n",
    "    # 1. Try (month, dayofweek, hour, minute)\n",
    "    mode1 = (\n",
    "        mode_df.groupby(['month', 'dayofweek', 'hour', 'minute'])[value_col]\n",
    "        .agg(lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan)\n",
    "        .reset_index()\n",
    "        .rename(columns={value_col: 'mode1'})\n",
    "    )\n",
    "    # 2. Try (month, dayofweek, hour)\n",
    "    mode2 = (\n",
    "        mode_df.groupby(['month', 'dayofweek', 'hour'])[value_col]\n",
    "        .agg(lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan)\n",
    "        .reset_index()\n",
    "        .rename(columns={value_col: 'mode2'})\n",
    "    )\n",
    "    # 3. Try (month, hour)\n",
    "    mode3 = (\n",
    "        mode_df.groupby(['month', 'hour'])[value_col]\n",
    "        .agg(lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan)\n",
    "        .reset_index()\n",
    "        .rename(columns={value_col: 'mode3'})\n",
    "    )\n",
    "    # 4. Try (hour)\n",
    "    mode4 = (\n",
    "        mode_df.groupby(['hour'])[value_col]\n",
    "        .agg(lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan)\n",
    "        .reset_index()\n",
    "        .rename(columns={value_col: 'mode4'})\n",
    "    )\n",
    "\n",
    "    df = df.reset_index().rename(columns={'index': datetime_col})\n",
    "    df = pd.merge(df, mode1, how='left', on=['month', 'dayofweek', 'hour', 'minute'])\n",
    "    df = pd.merge(df, mode2, how='left', on=['month', 'dayofweek', 'hour'])\n",
    "    df = pd.merge(df, mode3, how='left', on=['month', 'hour'])\n",
    "    df = pd.merge(df, mode4, how='left', on=['hour'])\n",
    "\n",
    "    def fillval(row):\n",
    "        if pd.notnull(row[value_col]):\n",
    "            return row[value_col]\n",
    "        for k in ['mode1', 'mode2', 'mode3', 'mode4']:\n",
    "            if pd.notnull(row[k]):\n",
    "                return row[k]\n",
    "        return np.nan\n",
    "\n",
    "    df[value_col] = df.apply(fillval, axis=1)\n",
    "    df[value_col] = df[value_col].ffill().bfill()\n",
    "    df = df[[datetime_col, value_col]].sort_values(by=datetime_col).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "raw_dir = 'raw'\n",
    "out_dir = 'processed'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "files = glob(os.path.join(raw_dir, '*.csv'))\n",
    "\n",
    "for file in files:\n",
    "    filename = os.path.basename(file)\n",
    "    try:\n",
    "        df = pd.read_csv(file, sep=';', usecols=['ts', 'vrednost'])\n",
    "        df['ts'] = pd.to_datetime(df['ts'], errors='coerce')\n",
    "        df['vrednost'] = df['vrednost'].str.replace(',', '.', regex=False).astype(float)\n",
    "        df['datetime'] = df['ts'].dt.floor('15min')\n",
    "\n",
    "        # Fill missing values as described in the paper\n",
    "        df = fill_missing_time_mode_monthly(df, datetime_col='datetime', value_col='vrednost')\n",
    "        df.rename(columns={\"vrednost\": \"load\"}, inplace=True)\n",
    "\n",
    "        out_path = os.path.join(out_dir, filename)\n",
    "        df.to_csv(out_path, index=False)\n",
    "        print(f\"‚úÖ Processed: {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed: {filename} ‚Äî {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
